
# ğŸ“˜ README.md

```markdown
# WOA-TOOL: Whale Optimization Algorithm vs Enhanced WOA

This project implements the **Whale Optimization Algorithm (WOA)** and an **Enhanced WOA (EWOA)** that integrates:
- Adaptive parameter tuning (dynamic adjustment of the `a` parameter)
- Opposition-Based Learning (OBL) to avoid local minima

The tool supports an **image-based classification pipeline** for breast cancer detection. It includes:
1. Preparing metadata from raw datasets
2. Preprocessing
3. Training a model (WOA or EWOA)
4. Predicting on new images

A **PHP-based frontend** is also included to run predictions via a web dashboard.

---

## ğŸ“‚ Project Structure

```

WOA-TOOL/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ woa_tool/                  # Core Python backend
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ adaptive.py
â”‚   â”œâ”€â”€ algorithms.py
â”‚   â”œâ”€â”€ cli.py                 # CLI entrypoint (preprocess, train, predict, etc.)
â”‚   â”œâ”€â”€ feature_extraction.py  # (if still used)
â”‚   â”œâ”€â”€ fitness.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â”œâ”€â”€ obl.py
â”‚   â”œâ”€â”€ predict.py             # prediction logic
â”‚   â”œâ”€â”€ prepare_metadata.py    # prepares CSV metadata from raw images
â”‚   â”œâ”€â”€ preprocess.py          # cleans/prepares datasets
â”‚   â”œâ”€â”€ train.py               # training logic (woa/ewoa)
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ php/                       # Frontend dashboard
â”‚   â”œâ”€â”€ index.php              # main UI for running predictions
â”‚   â”œâ”€â”€ config.php             # config (Python path, workdir, defaults)
â”‚   â””â”€â”€ test_uploads/          # temporary uploads (ignored in Git)
â”‚
â”œâ”€â”€ data/                      # (ignored) place datasets here
â”‚   â”œâ”€â”€ images/                # raw images (e.g., IMG001.tif)
â”‚   â”œâ”€â”€ train.csv              # generated metadata (after prepare_metadata)
â”‚   â”œâ”€â”€ test.csv               # optional test metadata
â”‚   â””â”€â”€ processed/             # cleaned CSVs & NumPy arrays (after preprocess)
â”‚
â”œâ”€â”€ models/                    # (ignored) trained models stored here
â”‚   â””â”€â”€ model.json
â”‚
â””â”€â”€ backups/                   # (optional) local backups (ignored)

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/WOA-TOOL.git
cd WOA-TOOL
````

### 2. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # On macOS/Linux
# OR
.venv\Scripts\activate      # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset Preparation

1. Place your dataset images inside `data/images/`.
   Example:

   ```
   data/images/
   â”œâ”€â”€ IMG001.tif
   â”œâ”€â”€ IMG002.tif
   â””â”€â”€ ...
   ```

2. Run the **metadata preparation script**:

   ```bash
   python3 woa_tool/prepare_metadata.py
   ```

   This generates `data/train.csv` and/or `data/test.csv` with the required format.

3. Run preprocessing:

   ```bash
   python3 -m woa_tool.cli preprocess
   ```

---

## â–¶ï¸ Training a Model

Train with WOA or EWOA. Example with EWOA:

```bash
python3 -m woa_tool.cli train \
  --data data/train.csv \
  --images data/images \
  --algo ewoa \
  --iters 100 \
  --pop 30 \
  --out models/model.json \
  --folds 5
```

Arguments:

* `--data` â†’ path to CSV file
* `--images` â†’ image folder
* `--algo` â†’ algorithm (`woa` or `ewoa`)
* `--iters` â†’ iterations
* `--pop` â†’ population size
* `--out` â†’ output path for trained model
* `--folds` â†’ cross-validation folds

---

## ğŸ” Predicting on a New Image

```bash
python3 -m woa_tool.cli predict \
  --model models/model.json \
  --image data/images/IMG012.tif
```

---

## ğŸŒ PHP Frontend Dashboard

1. Start PHP server:

   ```bash
   cd php
   php -S localhost:8000
   ```
2. Open `http://localhost:8000`

### Files of Interest

* `php/index.php` â€“ dashboard UI
* `php/config.php` â€“ config for Python path, workdir, defaults
* `php/test_uploads/` â€“ temp uploads (ignored)

---

## ğŸ“Š Data & Models

The following are excluded from GitHub but must exist locally:

* `data/` â†’ raw images + generated CSV metadata
* `models/` â†’ trained model files
* `php/test_uploads/` â†’ temp uploads

---

## ğŸ‘©â€ğŸ’» Authors

* **Backend & Research:** Python implementation of WOA/EWOA for preprocessing, training & prediction
* **Frontend:** PHP/Chart.js dashboard

---

## ğŸ“Œ Notes

* Always run `prepare_metadata` before `preprocess`.
* Datasets, models, and uploads are ignored in GitHub.
* This repo contains only the **code**, not the data/models.

```

---
- Step 1 â†’ run `prepare_metadata` (creates CSVs).  
- Step 2 â†’ `preprocess`.  
- Step 3 â†’ `train`.  
- Step 4 â†’ `predict` or use PHP frontend.  



## ğŸ”¬ How Images Are Processed into Numerical Features

The WOA-TOOL backend works with medical biopsy images (e.g., `.tif` files) and transforms them into numerical representations that can be optimized using **WOA/EWOA**.  
This ensures the algorithm can â€œseeâ€ the image in a form suitable for mathematical optimization.

### 1. Raw Data
- Input images are stored in `data/images/` (e.g., `IMG001.tif`, `IMG002.tif`).
- A metadata CSV (`train.csv`) links each image to its **label** (e.g., `benign`, `malignant`).

Example `train.csv`:
```csv
id,label
IMG001,benign
IMG002,malignant
IMG003,benign
````

---

### 2. Metadata Preparation

Run:

```bash
python3 -m woa_tool.cli prepare_metadata
```

This script:

* Scans `data/images/`
* Generates or validates `train.csv` and `test.csv`
* Ensures every image has a matching row in the metadata file

---

### 3. Preprocessing

Run:

```bash
python3 -m woa_tool.cli preprocess
```

This step:

* Converts each image into **numerical feature vectors** using image processing techniques.
* Typical calculations include:

  * **Shape features** â†’ area, perimeter, compactness
  * **Texture features** â†’ contrast, smoothness, entropy
  * **Intensity features** â†’ mean pixel value, variance
* Missing values are imputed (filled) where necessary.
* Normalization is applied so features are on a comparable scale.

Outputs:

* Cleaned CSVs (e.g., `processed_train.csv`)
* NumPy arrays (e.g., `X_train.npy`, `y_train.npy`) inside `data/processed/`

---

### 4. Labels

* The `label` column in the metadata file is mapped to numerical targets:

  * `benign` â†’ `0`
  * `malignant` â†’ `1`
* This allows optimization + training algorithms to work with numerical classification.

---

### 5. Training

Run:

```bash
python3 -m woa_tool.cli train \
  --data data/train.csv \
  --images data/images \
  --algo ewoa \
  --iters 100 \
  --pop 30 \
  --out models/model.json \
  --folds 5
```

Here:

* The extracted feature matrix (`X`) and label vector (`y`) are fed into the WOA/EWOA optimizer.
* WOA/EWOA searches for the **best feature subset and model parameters** that maximize classification accuracy.
* Output is saved as a trained model (`models/model.json`).

---

### 6. Prediction

Run:

```bash
python3 -m woa_tool.cli predict \
  --model models/model.json \
  --image data/images/IMG012.tif
```

* The image is processed into numerical features.
* Features are passed into the trained model.
* Output is a **predicted label** (e.g., â€œmalignantâ€) with supporting features that led to the decision.

---


