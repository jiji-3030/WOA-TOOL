Perfect â€” hereâ€™s the **updated and corrected `README.md`**, with a clear note that you **must run `prepare_metadata.py` first** before `preprocess`.

This is the *final, detailed academic-ready version*, suitable both for your manuscript documentation and GitHub repo.

---

## ğŸ§  Whale Optimization Algorithm (WOA) Tool

**Enhanced Feature Selection and Classification Framework for Breast Cancer Detection**

---

### ğŸ“˜ Overview

This repository implements a **comparative optimization tool** between the standard **Whale Optimization Algorithm (WOA)** and an **Enhanced Whale Optimization Algorithm (EWOA)** variant integrating:

* **Adaptive parameter tuning** (`a(t)` strategies such as `linear`, `sin`, `cos`, `tan`, `log`, `square`)
* **Opposition-Based Learning (OBL)** for improved exploration and convergence stability

The tool performs two main experiment types:

1. **Benchmark Optimization** â€” Evaluates WOA vs. EWOA on mathematical test functions.
2. **Feature Selection & Prediction** â€” Applies WOA/EWOA for selecting diagnostic features from the **Wisconsin Breast Cancer Dataset (WBCD)** and classifies new samples based on extracted image features.

---

### ğŸ§© Folder Structure

```
WOA-TOOL/
â”œâ”€â”€ woa_tool/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # Command-line interface entry point
â”‚   â”œâ”€â”€ preprocess.py       # Preprocessing: extracts image features
â”‚   â”œâ”€â”€ train.py            # Training: feature selection + model creation
â”‚   â”œâ”€â”€ predict.py          # Prediction: classify new images
â”‚   â”œâ”€â”€ algorithms.py       # Core WOA and EWOA logic
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ abnormality.py
â”‚   â”œâ”€â”€ prepare_metadata.py     # Generates train/test CSV manifests before preprocessing
â”‚   â””â”€â”€ ...
â”‚

â”‚
â”œâ”€â”€ php/                    # Web UI (PHP + Chart.js)
â”‚   â”œâ”€â”€ index.php
â”‚   â”œâ”€â”€ feature.php
â”‚   â”œâ”€â”€ config.php
â”‚   â””â”€â”€ assets/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/             # Image dataset (user-supplied)
â”‚   â”œâ”€â”€ train.csv           # Auto-generated by prepare_metadata.py
â”‚   â”œâ”€â”€ test.csv            # Auto-generated by prepare_metadata.py
â”‚   â”œâ”€â”€ csvs....
â”‚   â””â”€â”€ processed/          # Generated .npy arrays + feature_names.json
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model_ewoa_adaptive_obl.json
â”‚
â”œâ”€â”€ .venv/
â””â”€â”€ README.md
```

---

### âš™ï¸ Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/<your-username>/WOA-TOOL.git
cd WOA-TOOL
```

#### 2. Create and Activate Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # macOS/Linux
# OR
.venv\Scripts\activate      # Windows
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Configure PHP UI

Edit `php/config.php` to match your environment:

```php
return [
  'python_path' => '/Users/<user>/Documents/WOA-TOOL/.venv/bin/python3',
  'workdir'     => '/Users/<user>/Documents/WOA-TOOL',
  'defaults'    => [
    'runs' => 30,
    'iters' => 100,
    'pop' => 20,
    'dim' => 30
  ]
];
```

Then run the PHP server:

```bash
php -S localhost:8000 -t php
```

Visit: **[http://localhost:8000](http://localhost:8000)**

---

### ğŸ“Š Dataset Preparation

> âš ï¸ **Important:**
> Before preprocessing, you must first run the script `prepare_metadata.py` to generate the dataset metadata (train/test CSVs).

#### 1. Run `prepare_metadata.py`

This script scans the `data/images` directory, splits the dataset into training and testing sets, and generates:

```
data/train.csv
data/test.csv
```

Each CSV includes:

| patient_id | image_path             | Class |
| ---------- | ---------------------- | ----- |
| P001       | data/images/img001.png | B     |
| P002       | data/images/img002.png | M     |

Where:

* `B` = Benign (label 0)
* `M` = Malignant (label 1)

Run:

```bash
python3 prepare_metadata.py
```

âœ… Output:

```
Metadata prepared successfully.
Generated: data/train.csv, data/test.csv
```

---

### ğŸ§ª Step 2: Preprocess Dataset

Extracts image features and saves `.npy` arrays to `data/processed`.

```bash
python3 -m woa_tool.cli preprocess
```

Output:

```
ğŸ”„ Loading training set...
âœ… Preprocessing complete.
Train: (n_samples, n_features), Test: (n_samples, n_features)
```

---

### ğŸ§  Step 3: Train the Model

#### Example (Enhanced WOA with Adaptive + OBL)

```bash
python3 -m woa_tool.cli train \
  --processed data/processed \
  --algo ewoa \
  --iters 250 \
  --pop 50 \
  --a-strategy sin \
  --obl-freq 5 \
  --obl-rate 0.3 \
  --out models/model_ewoa_adaptive_obl.json \
  --folds 5
```

#### Example (Standard WOA)

```bash
python3 -m woa_tool.cli train \
  --processed data/processed \
  --algo woa \
  --iters 250 \
  --pop 50 \
  --out models/model_woa.json \
  --folds 5
```

Expected output:

```
âœ… Model saved to models/model_ewoa_adaptive_obl.json
Features: 30, Selected: 12
CV Error: 0.0475 (Benign err=0.0301, Malignant err=0.0648)
```

---

### ğŸ” Step 4: Predict on a New Image

```bash
python3 -m woa_tool.cli predict \
  --model models/model_ewoa_adaptive_obl.json \
  --image data/images/IMG001.png
```

Example output:

```json
{
  "final_prediction": "Malignant",
  "probabilities": {"Benign": 0.14, "Malignant": 0.86},
  "abnormality_type": "High-risk",
  "explanation": {
    "class": ["Top features contributing to Malignant classification"],
    "abnormality": {"texture_mean": 0.92, "area_worst": 0.88}
  },
  "selected_features_used": ["radius_mean", "texture_mean", "area_worst"],
  "algorithm": "ewoa",
  "meta": {"iters": 250, "pop": 50, "cv_error": 0.0475}
}
```

---

### ğŸ§¬ Algorithmic Enhancements

| Enhancement                         | Description                                                                                                                                                              |
| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Adaptive `a(t)` Strategy**        | Dynamically modifies the control parameter `a` using nonlinear functions (`sin`, `cos`, `tan`, `log`, `square`) for better balance between exploration and exploitation. |
| **Opposition-Based Learning (OBL)** | Periodically introduces opposite solutions (`obl_freq`, `obl_rate`) to expand the search space and escape local minima.                                                  |
| **Diversity-Aware Modulation**      | Monitors population diversity; increases exploration if solutions become too similar.                                                                                    |
| **Cross-Validation Evaluation**     | Uses `StratifiedKFold` for reliable average classification error.                                                                                                        |

---

### ğŸ§¾ Model JSON Structure

Each trained model file contains:

```json
{
  "feature_names": [...],
  "selected_idx": [...],
  "selected_names": [...],
  "algorithm": "ewoa",
  "iters": 250,
  "pop": 50,
  "error": 0.0475,
  "error_breakdown": {"Benign": 0.0301, "Malignant": 0.0648},
  "class_labels": {"0": "Benign", "1": "Malignant"},
  "class_stats": {"0": {"mu": [...], "sigma": [...]}, "1": {"mu": [...], "sigma": [...]}},
  "global_mu": [...],
  "global_sigma": [...]
}
```

