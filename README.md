Perfect — here’s the **updated and corrected `README.md`**, with a clear note that you **must run `prepare_metadata.py` first** before `preprocess`.

This is the *final, detailed academic-ready version*, suitable both for your manuscript documentation and GitHub repo.

---

## 🧠 Whale Optimization Algorithm (WOA) Tool

**Enhanced Feature Selection and Classification Framework for Breast Cancer Detection**

---

### 📘 Overview

This repository implements a **comparative optimization tool** between the standard **Whale Optimization Algorithm (WOA)** and an **Enhanced Whale Optimization Algorithm (EWOA)** variant integrating:

* **Adaptive parameter tuning** (`a(t)` strategies such as `linear`, `sin`, `cos`, `tan`, `log`, `square`)
* **Opposition-Based Learning (OBL)** for improved exploration and convergence stability

The tool performs two main experiment types:

1. **Benchmark Optimization** — Evaluates WOA vs. EWOA on mathematical test functions.
2. **Feature Selection & Prediction** — Applies WOA/EWOA for selecting diagnostic features from the **Wisconsin Breast Cancer Dataset (WBCD)** and classifies new samples based on extracted image features.

---

### 🧩 Folder Structure

```
WOA-TOOL/
├── woa_tool/
│   ├── __init__.py
│   ├── cli.py              # Command-line interface entry point
│   ├── preprocess.py       # Preprocessing: extracts image features
│   ├── train.py            # Training: feature selection + model creation
│   ├── predict.py          # Prediction: classify new images
│   ├── algorithms.py       # Core WOA and EWOA logic
│   ├── feature_extraction.py
│   ├── abnormality.py
│   ├── prepare_metadata.py     # Generates train/test CSV manifests before preprocessing
│   └── ...
│

│
├── php/                    # Web UI (PHP + Chart.js)
│   ├── index.php
│   ├── feature.php
│   ├── config.php
│   └── assets/
│
├── data/
│   ├── images/             # Image dataset (user-supplied)
│   ├── train.csv           # Auto-generated by prepare_metadata.py
│   ├── test.csv            # Auto-generated by prepare_metadata.py
│   ├── csvs....
│   └── processed/          # Generated .npy arrays + feature_names.json
│
├── models/
│   └── model_ewoa_adaptive_obl.json
│
├── .venv/
└── README.md
```

---

### ⚙️ Installation

#### 1. Clone the Repository

```bash
git clone https://github.com/<your-username>/WOA-TOOL.git
cd WOA-TOOL
```

#### 2. Create and Activate Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # macOS/Linux
# OR
.venv\Scripts\activate      # Windows
```

#### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

#### 4. Configure PHP UI

Edit `php/config.php` to match your environment:

```php
return [
  'python_path' => '/Users/<user>/Documents/WOA-TOOL/.venv/bin/python3',
  'workdir'     => '/Users/<user>/Documents/WOA-TOOL',
  'defaults'    => [
    'runs' => 30,
    'iters' => 100,
    'pop' => 20,
    'dim' => 30
  ]
];
```

Then run the PHP server:

```bash
php -S localhost:8000 -t php
```

Visit: **[http://localhost:8000](http://localhost:8000)**

---

### 📊 Dataset Preparation

> ⚠️ **Important:**
> Before preprocessing, you must first run the script `prepare_metadata.py` to generate the dataset metadata (train/test CSVs).

#### 1. Run `prepare_metadata.py`

This script scans the `data/images` directory, splits the dataset into training and testing sets, and generates:

```
data/train.csv
data/test.csv
```

Each CSV includes:

| patient_id | image_path             | Class |
| ---------- | ---------------------- | ----- |
| P001       | data/images/img001.png | B     |
| P002       | data/images/img002.png | M     |

Where:

* `B` = Benign (label 0)
* `M` = Malignant (label 1)

Run:

```bash
python3 prepare_metadata.py
```

✅ Output:

```
Metadata prepared successfully.
Generated: data/train.csv, data/test.csv
```

---

### 🧪 Step 2: Preprocess Dataset

Extracts image features and saves `.npy` arrays to `data/processed`.

```bash
python3 -m woa_tool.cli preprocess
```

Output:

```
🔄 Loading training set...
✅ Preprocessing complete.
Train: (n_samples, n_features), Test: (n_samples, n_features)
```

---

### 🧠 Step 3: Train the Model

#### Example (Enhanced WOA with Adaptive + OBL)

```bash
python3 -m woa_tool.cli train \
  --processed data/processed \
  --algo ewoa \
  --iters 250 \
  --pop 50 \
  --a-strategy sin \
  --obl-freq 5 \
  --obl-rate 0.3 \
  --out models/model_ewoa_adaptive_obl.json \
  --folds 5
```

#### Example (Standard WOA)

```bash
python3 -m woa_tool.cli train \
  --processed data/processed \
  --algo woa \
  --iters 250 \
  --pop 50 \
  --out models/model_woa.json \
  --folds 5
```

Expected output:

```
✅ Model saved to models/model_ewoa_adaptive_obl.json
Features: 30, Selected: 12
CV Error: 0.0475 (Benign err=0.0301, Malignant err=0.0648)
```

---

### 🔍 Step 4: Predict on a New Image

```bash
python3 -m woa_tool.cli predict \
  --model models/model_ewoa_adaptive_obl.json \
  --image data/images/IMG001.png
```

Example output:

```json
{
  "final_prediction": "Malignant",
  "probabilities": {"Benign": 0.14, "Malignant": 0.86},
  "abnormality_type": "High-risk",
  "explanation": {
    "class": ["Top features contributing to Malignant classification"],
    "abnormality": {"texture_mean": 0.92, "area_worst": 0.88}
  },
  "selected_features_used": ["radius_mean", "texture_mean", "area_worst"],
  "algorithm": "ewoa",
  "meta": {"iters": 250, "pop": 50, "cv_error": 0.0475}
}
```

---

### 🧬 Algorithmic Enhancements

| Enhancement                         | Description                                                                                                                                                              |
| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Adaptive `a(t)` Strategy**        | Dynamically modifies the control parameter `a` using nonlinear functions (`sin`, `cos`, `tan`, `log`, `square`) for better balance between exploration and exploitation. |
| **Opposition-Based Learning (OBL)** | Periodically introduces opposite solutions (`obl_freq`, `obl_rate`) to expand the search space and escape local minima.                                                  |
| **Diversity-Aware Modulation**      | Monitors population diversity; increases exploration if solutions become too similar.                                                                                    |
| **Cross-Validation Evaluation**     | Uses `StratifiedKFold` for reliable average classification error.                                                                                                        |

---

### 🧾 Model JSON Structure

Each trained model file contains:

```json
{
  "feature_names": [...],
  "selected_idx": [...],
  "selected_names": [...],
  "algorithm": "ewoa",
  "iters": 250,
  "pop": 50,
  "error": 0.0475,
  "error_breakdown": {"Benign": 0.0301, "Malignant": 0.0648},
  "class_labels": {"0": "Benign", "1": "Malignant"},
  "class_stats": {"0": {"mu": [...], "sigma": [...]}, "1": {"mu": [...], "sigma": [...]}},
  "global_mu": [...],
  "global_sigma": [...]
}
```

