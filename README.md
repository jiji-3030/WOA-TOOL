Ahhh perfect ğŸ‘Œ thanks for pointing that out. That means instead of manually telling users how to prepare `train.csv`, we should explain that they must run your **`prepare_metadata.py`** step before `preprocess`.

Let me rewrite the README so it matches your actual CLI workflow:

---

# ğŸ“˜ README.md (with `prepare_metadata.py`)

```markdown
# WOA-TOOL: Whale Optimization Algorithm vs Enhanced WOA

This project implements the **Whale Optimization Algorithm (WOA)** and an **Enhanced WOA (EWOA)** that integrates:
- Adaptive parameter tuning (dynamic adjustment of the `a` parameter)
- Opposition-Based Learning (OBL) to avoid local minima

The tool supports an **image-based classification pipeline** for breast cancer detection. It includes:
1. Preparing metadata from raw datasets
2. Preprocessing
3. Training a model (WOA or EWOA)
4. Predicting on new images

A **PHP-based frontend** is also included to run predictions via a web dashboard.

---

## ğŸ“‚ Project Structure

```

WOA-TOOL/
â”œâ”€â”€ woa_tool/
â”‚   â”œâ”€â”€ prepare_metadata.py # Creates train/test CSVs from raw dataset
â”‚   â”œâ”€â”€ preprocess.py       # Cleans & preprocesses data
â”‚   â”œâ”€â”€ train.py            # Training logic
â”‚   â”œâ”€â”€ predict.py          # Prediction logic
â”‚   â””â”€â”€ ...
â”œâ”€â”€ php/
â”‚   â”œâ”€â”€ index.php           # Main dashboard
â”‚   â”œâ”€â”€ config.php          # Config for paths & defaults
â”‚   â””â”€â”€ test_uploads/       # Temp uploads (ignored)
â”œâ”€â”€ data/                   # (Ignored in Git) place raw images/datasets here
â”œâ”€â”€ models/                 # (Ignored in Git) trained model output
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/WOA-TOOL.git
cd WOA-TOOL
````

### 2. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate   # On macOS/Linux
# OR
.venv\Scripts\activate      # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Dataset Preparation

1. Place your dataset images inside `data/images/`.
   Example:

   ```
   data/images/
   â”œâ”€â”€ IMG001.tif
   â”œâ”€â”€ IMG002.tif
   â””â”€â”€ ...
   ```

2. Run the **metadata preparation script**:

   ```bash
   python3 -m woa_tool.cli prepare_metadata
   ```

   This generates `data/train.csv` and/or `data/test.csv` with the required format.

3. Run preprocessing:

   ```bash
   python3 -m woa_tool.cli preprocess
   ```

---

## â–¶ï¸ Training a Model

Train with WOA or EWOA. Example with EWOA:

```bash
python3 -m woa_tool.cli train \
  --data data/train.csv \
  --images data/images \
  --algo ewoa \
  --iters 100 \
  --pop 30 \
  --out models/model.json \
  --folds 5
```

Arguments:

* `--data` â†’ path to CSV file
* `--images` â†’ image folder
* `--algo` â†’ algorithm (`woa` or `ewoa`)
* `--iters` â†’ iterations
* `--pop` â†’ population size
* `--out` â†’ output path for trained model
* `--folds` â†’ cross-validation folds

---

## ğŸ” Predicting on a New Image

```bash
python3 -m woa_tool.cli predict \
  --model models/model.json \
  --image data/images/IMG012.tif
```

---

## ğŸŒ PHP Frontend Dashboard

1. Start PHP server:

   ```bash
   cd php
   php -S localhost:8000
   ```
2. Open `http://localhost:8000`

### Files of Interest

* `php/index.php` â€“ dashboard UI
* `php/config.php` â€“ config for Python path, workdir, defaults
* `php/test_uploads/` â€“ temp uploads (ignored)

---

## ğŸ“Š Data & Models

The following are excluded from GitHub but must exist locally:

* `data/` â†’ raw images + generated CSV metadata
* `models/` â†’ trained model files
* `php/test_uploads/` â†’ temp uploads

---

## ğŸ‘©â€ğŸ’» Authors

* **Backend & Research:** Python implementation of WOA/EWOA for preprocessing, training & prediction
* **Frontend:** PHP/Chart.js dashboard

---

## ğŸ“Œ Notes

* Always run `prepare_metadata` before `preprocess`.
* Datasets, models, and uploads are ignored in GitHub.
* This repo contains only the **code**, not the data/models.

```

---
- Step 1 â†’ run `prepare_metadata` (creates CSVs).  
- Step 2 â†’ `preprocess`.  
- Step 3 â†’ `train`.  
- Step 4 â†’ `predict` or use PHP frontend.  
